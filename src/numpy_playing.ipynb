{
 "metadata": {
  "name": "",
  "signature": "sha256:5f1be3749200ff7d146641a2a5d0e828487658db608e86e7a4183d3c76c104e4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import utils as utils\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import csv\n",
      "from pprint import pprint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename = '../data/vocabulary.txt'\n",
      "vocab = m.read_file_dict(filename)\n",
      "train_labels = m.read_file_dict(\"../data/train.label\")\n",
      "with open('../data/train.map') as mapfile:\n",
      "    reader = csv.reader(mapfile, delimiter=' ')\n",
      "    #for line in reader:\n",
      "     #   print(line)\n",
      "    label_map = {int(line[1]):line[0] for line in reader}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a = m.gen_agg_file(vocab, '../data/train', train_labels)\n",
      "bow = np.loadtxt('../data/train.full', dtype='int32')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "b = bow[bow[:,0] == 101]\n",
      "print(b.shape)\n",
      "vocab[b[30][1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50, 4)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "['away']"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tester(vocabs, model, docid):\n",
      "    b = model[model[:,0] == docid]\n",
      "    words = [ vocabs[b[i][1]][0] for i in range(0,b.shape[0]) ] \n",
      "    return words\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "docid = 101\n",
      "w = tester(vocab, bow, 101)\n",
      "print(w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['of', 'and', 'the', 'in', 'it', 'get', 'com', 'for', 'they', 'that', 'this', 'at', 'you', 'what', 'article', 'edu', 'writes', 'could', 'mean', 'out', 'your', 'stay', 'until', 'bobbe', 'vice', 'ico', 'tek', 'beauchaine', 'really', 'said', 'away', 'bobby', 'apr', 'sig', 'ultb', 'isc', 'rit', 'snm', 'mozumder', 'peace', 'bob', 'queens', 'blew', 'bronx', 'sank', 'manhattan', 'sea', 'hell', 'learn', 'stands']\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label_map[b[49][3]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "'alt.atheism'"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = m.get_words_from_doc(101, bow, vocab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['of', 'and', 'the', 'in', 'it', 'get', 'com', 'for', 'they', 'that', 'this', 'at', 'you', 'what', 'article', 'edu', 'writes', 'could', 'mean', 'out', 'your', 'stay', 'until', 'bobbe', 'vice', 'ico', 'tek', 'beauchaine', 'really', 'said', 'away', 'bobby', 'apr', 'sig', 'ultb', 'isc', 'rit', 'snm', 'mozumder', 'peace', 'bob', 'queens', 'blew', 'bronx', 'sank', 'manhattan', 'sea', 'hell', 'learn', 'stands']\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "labels = np.zeros(docid.shape, dtype='int8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'int' object has no attribute 'shape'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-17-38931aafd31a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(docid.size):\n",
      "    lab = docid[i]\n",
      "    labels[i] = train_labels[lab][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "array([ 1,  1,  1, ..., 20, 20, 20], dtype=int8)"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bow.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "(1467345,)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bow = np.column_stack((docid, wordid, count, labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bow.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "dtype('int32')"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bow"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([[    1,     1,     4,     1],\n",
        "       [    1,     2,     2,     1],\n",
        "       [    1,     3,    10,     1],\n",
        "       ..., \n",
        "       [11269, 48919,     1,    20],\n",
        "       [11269, 51544,     1,    20],\n",
        "       [11269, 53958,     1,    20]], dtype=int32)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bow[:,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "array([    1,     1,     1, ..., 11269, 11269, 11269], dtype=int32)"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data = np.loadtxt('../data/train.full', dtype='uint16', )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_vocab = utils.read_file_dict('../data/vocabulary.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label_map = utils.read_mapfile('../data/train.map')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([[    1,     1,     4,     1],\n",
        "       [    1,     2,     2,     1],\n",
        "       [    1,     3,    10,     1],\n",
        "       ..., \n",
        "       [11269, 48919,     1,    20],\n",
        "       [11269, 51544,     1,    20],\n",
        "       [11269, 53958,     1,    20]], dtype=uint16)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "train_prior = {}\n",
      "vec = train_data[:,3]\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(1,21):\n",
      "    view = vec[vec == i]\n",
      "    train_prior[label_map[i]] = view.size/vec.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(train_data.size)\n",
      "pprint(train_prior)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5869380\n",
        "{}\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_priors = utils.estimate_priors(label_map, vec)\n",
      "pprint(train_priors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'alt.atheism': 0.04973472496243215,\n",
        " 'comp.graphics': 0.03984884263755286,\n",
        " 'comp.os.ms-windows.misc': 0.03736203823913258,\n",
        " 'comp.sys.ibm.pc.hardware': 0.03930364024820339,\n",
        " 'comp.sys.mac.hardware': 0.03619734963488477,\n",
        " 'comp.windows.x': 0.04659572220575257,\n",
        " 'misc.forsale': 0.028811220265172813,\n",
        " 'rec.autos': 0.04723224599531808,\n",
        " 'rec.motorcycles': 0.045334941680381914,\n",
        " 'rec.sport.baseball': 0.044625497071240916,\n",
        " 'rec.sport.hockey': 0.0525384282496618,\n",
        " 'sci.crypt': 0.06796152234137166,\n",
        " 'sci.electronics': 0.041876995525932895,\n",
        " 'sci.med': 0.058204444080976185,\n",
        " 'sci.space': 0.057467739352367715,\n",
        " 'soc.religion.christian': 0.06856397098160283,\n",
        " 'talk.politics.guns': 0.06309968003434775,\n",
        " 'talk.politics.mideast': 0.0772333704752461,\n",
        " 'talk.politics.misc': 0.05740981159849933,\n",
        " 'talk.religion.misc': 0.0405978144199217}\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vec.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "(1467345,)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = train_data[train_data[:, 0] == 900]\n",
      "d = train_data[train_data[:, 0] == 1010]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t.size\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "128"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "440"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this doc is weird\n",
      "words_from = utils.get_words_from_doc(9946, train_data, train_vocab)\n",
      "print(words_from)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['last', 'of', 'from', 'and', 'other', 'are', 'the', 'in', 'us', 'to', 'it', 'like', 'on', 'their', 'but', 'with', 'written', 'is', 'people', 'can', 'try', 'com', 'for', 'who', 'go', 'price', 'so', 'one', 'such', 'by', 'or', 'an', 'may', 'be', 'older', 'they', 'south', 'place', 'that', 'all', 'any', 'well', 'this', 'lives', 'set', 'at', 'very', 'about', 'truth', 'rather', 'than', 'often', 'some', 'women', 'remote', 'demand', 'death', 'its', 'after', 'reality', 'into', 'young', 'as', 'right', 'under', 'own', 'only', 'old', 'first', 'more', 'work', 'has', 'if', 'you', 'know', 'what', 'make', 'sure', 'seems', 'even', 'etc', 'die', 'great', 'most', 'case', 'against', 'comprehensive', 'best', 'way', 'view', 'kind', 'statements', 'men', 'was', 'were', 'moral', 'those', 'concept', 'better', 'hand', 'murder', 'not', 'there', 'small', 'information', 'will', 'back', 'article', 'writes', 'answering', 'our', 'questions', 'question', 'could', 'resulted', 'we', 'did', 'these', 'just', 'much', 'nothing', 'me', 'do', 'called', 'no', 'since', 'deal', 'up', 'yes', 'now', 'have', 'little', 'asking', 'should', 'end', 'killing', 'innocent', 'your', 'claim', 'wrong', 'want', 'fine', 'every', 'am', 'between', 'say', 'my', 'would', 'answer', 'before', 'where', 'years', 'specifically', 'too', 'until', 'going', 'killed', 'result', 'kill', 'taking', 'situation', 'either', 'myself', 'bit', 'usually', 'solely', 'necessary', 'similar', 'really', 'once', 'irrelevant', 'concerned', 'blood', 'others', 'members', 'accept', 'circumstances', 'time', 'issue', 'though', 'able', 'yourself', 'fact', 'free', 'matter', 'opinion', 're', 'allow', 'cannot', 'important', 'realize', 'hope', 'maybe', 'along', 'ask', 'agree', 'interested', 'bad', 'problem', 'act', 'real', 'attacks', 'occurs', 'consider', 'cold', 'come', 'policy', 'feel', 'telling', 'basis', 'far', 'home', 'imagine', 'caused', 'troops', 'happened', 'apr', 'give', 'strikes', 'thread', 'removal', 'hard', 'government', 'already', 'figure', 'talks', 'soldiers', 'fields', 'jews', 'failed', 'stop', 'supported', 'accurate', 'conclusion', 'pay', 'year', 'public', 'finding', 'force', 'responsible', 'newsgroup', 'advance', 'attacked', 'bunch', 'controlling', 'business', 'heavy', 'save', 'nobody', 'wants', 'comments', 'coffee', 'drink', 'hold', 'pressure', 'ignorant', 'peace', 'candidate', 'proven', 'cities', 'whereby', 'communities', 'terrorism', 'deaths', 'side', 'knows', 'three', 'compare', 'solution', 'playing', 'image', 'shell', 'parts', 'occasional', 'protection', 'ground', 'proper', 'hearted', 'efforts', 'addressed', 'kids', 'summer', 'camp', 'streets', 'militarily', 'unilaterally', 'move', 'israel', 'girl', 'protect', 'picture', 'capable', 'land', 'israeli', 'offered', 'iran', 'camps', 'borders', 'keeping', 'bomb', 'protecting', 'feeling', 'announce', 'daily', 'st', 'warn', 'quarrel', 'hurt', 'cards', 'gonna', 'resistance', 'occupation', 'civilians', 'attacking', 'terrorist', 'exercise', 'qualified', 'incentive', 'filled', 'bombs', 'security', 'choosing', 'civilian', 'bombing', 'bombed', 'lift', 'suspect', 'receiving', 'injured', 'lunch', 'insists', 'regular', 'aimed', 'northern', 'misinformation', 'southern', 'border', 'buffer', 'colored', 'unocal', 'edge', 'heavily', 'paint', 'arms', 'realistic', 'rightly', 'establishment', 'toll', 'genuinely', 'shop', 'preparing', 'soccer', 'traps', 'munich', 'zone', 'occupied', 'shops', 'insure', 'hurting', 'village', 'brave', 'soldier', 'aged', 'tactics', 'eliminating', 'pilots', 'condone', 'justifies', 'patrol', 'accustomed', 'financially', 'settlement', 'leverage', 'athletes', 'secretive', 'withdraw', 'sneak', 'shelled', 'concessions', 'basil', 'terrorists', 'abroad', 'disarmed', 'withdrawal', 'militias', 'disarming', 'inhabitants', 'occupying', 'indiscriminate', 'lebanon', 'diverting', 'stationed', 'villages', 'indiscriminately', 'ammunitions', 'israelis', 'dorin', 'stssdxb', 'baru', 'negociations', 'syrian', 'lebanese', 'shelling', 'iraelis', 'booby', 'terrritory', 'disingeneous', 'mrder', 'coffe', 'patrols', 'retalliates', 'hideout', 'villagers', 'retalliation', 'withdraws', 'hizbollah', 'goovernment', 'isareli']\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "MLE for $P(Y_k)$\n",
      "$$P(Y_k) = \\frac{\\#\\ of\\ docs\\ labeled\\ Y_k}{total\\ \\#\\ of\\ docs}$$\n",
      "\n",
      "\n",
      "MAP for $P(X_i|Y_k)$\n",
      "\n",
      "$$P(X_i|Y_k) = \\frac{(count\\ of\\ X_i\\ in\\ Y_k)+(\\alpha -1)}{(total\\ words\\ in Y_k)+((\\alpha - 1)*(length\\ of\\ vocab\\ list)))}$$\n",
      "\n",
      "Where \n",
      "$\\alpha = 1 + \\beta$\n",
      "\n",
      "And classify\n",
      "$$Y^{new} = argmax \\big[\\ log_2(P(Y_k)) + \\sum_{i}(\\#\\ of\\ X^{new}_i)log_2(P(X_i|Y_k))\\big]$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Possibly make a new numpy array for d's priors\n",
      "\n",
      " docid |class | c_1 ... c_20  \n",
      "-------|------|----------------\n",
      " 1     |  2   | 0.1 \n",
      " \n",
      " And one for words:\n",
      " \n",
      "  wordid |class | p_hat\n",
      "-------|------|----------------\n",
      " 1     |  1   | 0.1\n",
      " 1     |  2   | 0.02\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# select all words from a class\n",
      "word_class = train_data[train_data[:, 3] == 1]\n",
      "word_class.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "291912"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_class.size\n",
      "len(train_vocab.keys())\n",
      "word_phat = np.zeros((len(train_vocab.keys()),2))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_counts = np.zeros((len(train_vocab.keys()),4))\n",
      "\n",
      "# count = train_data[train_data[:, 1] == 1]\n",
      "#print(count)\n",
      "#print(count[2].sum())\n",
      "\n",
      "countsum_words = []\n",
      "for i in range(0,word_counts.size):\n",
      "    count = count[count[:, 1] == i]\n",
      "    for i in range(0,21):\n",
      "        # return view over single classes\n",
      "        class_view = count[count[:,2] == i]\n",
      "        # gets scalar sum for the counts in the view\n",
      "        # and returns just that scalar value; Numpy returns an array\n",
      "        class_sum = class_view.sum(axis = 0)[2]\n",
      "        countsum_words.append(class_sum)\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "21\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(0, 21):\n",
      "    tmp = train_data[train_data[:, 1] == i]\n",
      "    counts = tmp.cumsum(2)\n",
      "    word_counts[i,1] = counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(0, word_class.size):\n",
      "    tmp = word_class[word_class[:, 1] == i]\n",
      "    counts = tmp.cumsum(2)\n",
      "    word_phat[i,1] = counts/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}