{
 "metadata": {
  "name": "",
  "signature": "sha256:6f24a791802deb59ce6814a9d325dcbc1f53e9874b0bd67f056e35129037afd0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import utils as utils\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import csv\n",
      "from pprint import pprint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename = '../data/vocabulary.txt'\n",
      "vocab = utils.read_file_dict(filename)\n",
      "train_labels = utils.read_file_dict(\"../data/train.label\")\n",
      "with open('../data/train.map') as mapfile:\n",
      "    reader = csv.reader(mapfile, delimiter=' ')\n",
      "    #for line in reader:\n",
      "     #   print(line)\n",
      "    label_map = {int(line[1]):line[0] for line in reader}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a = m.gen_agg_file(vocab, '../data/train', train_labels)\n",
      "bow = np.loadtxt('../data/train.full', dtype='int32')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "b = bow[bow[:,0] == 101]\n",
      "print(b.shape)\n",
      "vocab[b[30][1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50, 4)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "['away']"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tester(vocabs, model, docid):\n",
      "    b = model[model[:,0] == docid]\n",
      "    words = [ vocabs[b[i][1]][0] for i in range(0,b.shape[0]) ] \n",
      "    return words\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "docid = 101\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label_map[b[49][3]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "'alt.atheism'"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = utils.get_words_from_doc(101, bow, vocab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['of', 'and', 'the', 'in', 'it', 'get', 'com', 'for', 'they', 'that', 'this', 'at', 'you', 'what', 'article', 'edu', 'writes', 'could', 'mean', 'out', 'your', 'stay', 'until', 'bobbe', 'vice', 'ico', 'tek', 'beauchaine', 'really', 'said', 'away', 'bobby', 'apr', 'sig', 'ultb', 'isc', 'rit', 'snm', 'mozumder', 'peace', 'bob', 'queens', 'blew', 'bronx', 'sank', 'manhattan', 'sea', 'hell', 'learn', 'stands']\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "labels = np.zeros(docid.shape, dtype='int8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'int' object has no attribute 'shape'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-14-38931aafd31a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(docid.size):\n",
      "    lab = docid[i]\n",
      "    labels[i] = train_labels[lab][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'int' object has no attribute 'size'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-15-61cb423b64ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'size'"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "array([ 1,  1,  1, ..., 20, 20, 20], dtype=int8)"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bow.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "(1467345, 4)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bow = np.column_stack((docid, wordid, count, labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bow.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "dtype('int32')"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bow"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([[    1,     1,     4,     1],\n",
        "       [    1,     2,     2,     1],\n",
        "       [    1,     3,    10,     1],\n",
        "       ..., \n",
        "       [11269, 48919,     1,    20],\n",
        "       [11269, 51544,     1,    20],\n",
        "       [11269, 53958,     1,    20]], dtype=int32)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bow[:,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "array([    1,     1,     1, ..., 11269, 11269, 11269], dtype=int32)"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data = np.loadtxt('../data/train.full', dtype='uint16', )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_vocab = utils.read_file_dict('../data/vocabulary.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label_map = utils.read_mapfile('../data/train.map')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "array([[    1,     1,     4,     1],\n",
        "       [    1,     2,     2,     1],\n",
        "       [    1,     3,    10,     1],\n",
        "       ..., \n",
        "       [11269, 48919,     1,    20],\n",
        "       [11269, 51544,     1,    20],\n",
        "       [11269, 53958,     1,    20]], dtype=uint16)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "train_prior = {}\n",
      "vec = train_data[:,3]\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(1,21):\n",
      "    view = vec[vec == i]\n",
      "    train_prior[label_map[i]] = view.size/vec.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(train_data.size)\n",
      "pprint(train_prior)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5869380\n",
        "{'alt.atheism': 0.04973472496243215,\n",
        " 'comp.graphics': 0.03984884263755286,\n",
        " 'comp.os.ms-windows.misc': 0.03736203823913258,\n",
        " 'comp.sys.ibm.pc.hardware': 0.03930364024820339,\n",
        " 'comp.sys.mac.hardware': 0.03619734963488477,\n",
        " 'comp.windows.x': 0.04659572220575257,\n",
        " 'misc.forsale': 0.028811220265172813,\n",
        " 'rec.autos': 0.04723224599531808,\n",
        " 'rec.motorcycles': 0.045334941680381914,\n",
        " 'rec.sport.baseball': 0.044625497071240916,\n",
        " 'rec.sport.hockey': 0.0525384282496618,\n",
        " 'sci.crypt': 0.06796152234137166,\n",
        " 'sci.electronics': 0.041876995525932895,\n",
        " 'sci.med': 0.058204444080976185,\n",
        " 'sci.space': 0.057467739352367715,\n",
        " 'soc.religion.christian': 0.06856397098160283,\n",
        " 'talk.politics.guns': 0.06309968003434775,\n",
        " 'talk.politics.mideast': 0.0772333704752461,\n",
        " 'talk.politics.misc': 0.05740981159849933,\n",
        " 'talk.religion.misc': 0.0405978144199217}\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_priors = utils.estimate_priors(label_map, vec)\n",
      "pprint(train_priors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'alt.atheism': 0.04973472496243215,\n",
        " 'comp.graphics': 0.03984884263755286,\n",
        " 'comp.os.ms-windows.misc': 0.03736203823913258,\n",
        " 'comp.sys.ibm.pc.hardware': 0.03930364024820339,\n",
        " 'comp.sys.mac.hardware': 0.03619734963488477,\n",
        " 'comp.windows.x': 0.04659572220575257,\n",
        " 'misc.forsale': 0.028811220265172813,\n",
        " 'rec.autos': 0.04723224599531808,\n",
        " 'rec.motorcycles': 0.045334941680381914,\n",
        " 'rec.sport.baseball': 0.044625497071240916,\n",
        " 'rec.sport.hockey': 0.0525384282496618,\n",
        " 'sci.crypt': 0.06796152234137166,\n",
        " 'sci.electronics': 0.041876995525932895,\n",
        " 'sci.med': 0.058204444080976185,\n",
        " 'sci.space': 0.057467739352367715,\n",
        " 'soc.religion.christian': 0.06856397098160283,\n",
        " 'talk.politics.guns': 0.06309968003434775,\n",
        " 'talk.politics.mideast': 0.0772333704752461,\n",
        " 'talk.politics.misc': 0.05740981159849933,\n",
        " 'talk.religion.misc': 0.0405978144199217}\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vec.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "(1467345,)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = train_data[train_data[:, 0] == 900]\n",
      "d = train_data[train_data[:, 0] == 1010]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t.size\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "128"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "440"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this doc is weird\n",
      "words_from = utils.get_words_from_doc(9946, train_data, train_vocab)\n",
      "print(words_from)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['last', 'of', 'from', 'and', 'other', 'are', 'the', 'in', 'us', 'to', 'it', 'like', 'on', 'their', 'but', 'with', 'written', 'is', 'people', 'can', 'try', 'com', 'for', 'who', 'go', 'price', 'so', 'one', 'such', 'by', 'or', 'an', 'may', 'be', 'older', 'they', 'south', 'place', 'that', 'all', 'any', 'well', 'this', 'lives', 'set', 'at', 'very', 'about', 'truth', 'rather', 'than', 'often', 'some', 'women', 'remote', 'demand', 'death', 'its', 'after', 'reality', 'into', 'young', 'as', 'right', 'under', 'own', 'only', 'old', 'first', 'more', 'work', 'has', 'if', 'you', 'know', 'what', 'make', 'sure', 'seems', 'even', 'etc', 'die', 'great', 'most', 'case', 'against', 'comprehensive', 'best', 'way', 'view', 'kind', 'statements', 'men', 'was', 'were', 'moral', 'those', 'concept', 'better', 'hand', 'murder', 'not', 'there', 'small', 'information', 'will', 'back', 'article', 'writes', 'answering', 'our', 'questions', 'question', 'could', 'resulted', 'we', 'did', 'these', 'just', 'much', 'nothing', 'me', 'do', 'called', 'no', 'since', 'deal', 'up', 'yes', 'now', 'have', 'little', 'asking', 'should', 'end', 'killing', 'innocent', 'your', 'claim', 'wrong', 'want', 'fine', 'every', 'am', 'between', 'say', 'my', 'would', 'answer', 'before', 'where', 'years', 'specifically', 'too', 'until', 'going', 'killed', 'result', 'kill', 'taking', 'situation', 'either', 'myself', 'bit', 'usually', 'solely', 'necessary', 'similar', 'really', 'once', 'irrelevant', 'concerned', 'blood', 'others', 'members', 'accept', 'circumstances', 'time', 'issue', 'though', 'able', 'yourself', 'fact', 'free', 'matter', 'opinion', 're', 'allow', 'cannot', 'important', 'realize', 'hope', 'maybe', 'along', 'ask', 'agree', 'interested', 'bad', 'problem', 'act', 'real', 'attacks', 'occurs', 'consider', 'cold', 'come', 'policy', 'feel', 'telling', 'basis', 'far', 'home', 'imagine', 'caused', 'troops', 'happened', 'apr', 'give', 'strikes', 'thread', 'removal', 'hard', 'government', 'already', 'figure', 'talks', 'soldiers', 'fields', 'jews', 'failed', 'stop', 'supported', 'accurate', 'conclusion', 'pay', 'year', 'public', 'finding', 'force', 'responsible', 'newsgroup', 'advance', 'attacked', 'bunch', 'controlling', 'business', 'heavy', 'save', 'nobody', 'wants', 'comments', 'coffee', 'drink', 'hold', 'pressure', 'ignorant', 'peace', 'candidate', 'proven', 'cities', 'whereby', 'communities', 'terrorism', 'deaths', 'side', 'knows', 'three', 'compare', 'solution', 'playing', 'image', 'shell', 'parts', 'occasional', 'protection', 'ground', 'proper', 'hearted', 'efforts', 'addressed', 'kids', 'summer', 'camp', 'streets', 'militarily', 'unilaterally', 'move', 'israel', 'girl', 'protect', 'picture', 'capable', 'land', 'israeli', 'offered', 'iran', 'camps', 'borders', 'keeping', 'bomb', 'protecting', 'feeling', 'announce', 'daily', 'st', 'warn', 'quarrel', 'hurt', 'cards', 'gonna', 'resistance', 'occupation', 'civilians', 'attacking', 'terrorist', 'exercise', 'qualified', 'incentive', 'filled', 'bombs', 'security', 'choosing', 'civilian', 'bombing', 'bombed', 'lift', 'suspect', 'receiving', 'injured', 'lunch', 'insists', 'regular', 'aimed', 'northern', 'misinformation', 'southern', 'border', 'buffer', 'colored', 'unocal', 'edge', 'heavily', 'paint', 'arms', 'realistic', 'rightly', 'establishment', 'toll', 'genuinely', 'shop', 'preparing', 'soccer', 'traps', 'munich', 'zone', 'occupied', 'shops', 'insure', 'hurting', 'village', 'brave', 'soldier', 'aged', 'tactics', 'eliminating', 'pilots', 'condone', 'justifies', 'patrol', 'accustomed', 'financially', 'settlement', 'leverage', 'athletes', 'secretive', 'withdraw', 'sneak', 'shelled', 'concessions', 'basil', 'terrorists', 'abroad', 'disarmed', 'withdrawal', 'militias', 'disarming', 'inhabitants', 'occupying', 'indiscriminate', 'lebanon', 'diverting', 'stationed', 'villages', 'indiscriminately', 'ammunitions', 'israelis', 'dorin', 'stssdxb', 'baru', 'negociations', 'syrian', 'lebanese', 'shelling', 'iraelis', 'booby', 'terrritory', 'disingeneous', 'mrder', 'coffe', 'patrols', 'retalliates', 'hideout', 'villagers', 'retalliation', 'withdraws', 'hizbollah', 'goovernment', 'isareli']\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "MLE for $P(Y_k)$\n",
      "$$P(Y_k) = \\frac{\\#\\ of\\ docs\\ labeled\\ Y_k}{total\\ \\#\\ of\\ docs}$$\n",
      "\n",
      "\n",
      "MAP for $P(X_i|Y_k)$\n",
      "\n",
      "$$P(X_i|Y_k) = \\frac{(count\\ of\\ X_i\\ in\\ Y_k)+(\\alpha -1)}{(total\\ words\\ in Y_k)+((\\alpha - 1)*(length\\ of\\ vocab\\ list)))}$$\n",
      "\n",
      "Where \n",
      "$\\alpha = 1 + \\beta$\n",
      "\n",
      "And classify\n",
      "$$Y^{new} = argmax \\big[\\ log_2(P(Y_k)) + \\sum_{i}(\\#\\ of\\ X^{new}_i)log_2(P(X_i|Y_k))\\big]$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Possibly make a new numpy array for d's priors\n",
      "\n",
      " docid |class | c_1 ... c_20  \n",
      "-------|------|----------------\n",
      " 1     |  2   | 0.1 \n",
      " \n",
      " And one for words:\n",
      " \n",
      "  wordid |class | p_hat\n",
      "-------|------|----------------\n",
      " 1     |  1   | 0.1\n",
      " 1     |  2   | 0.02\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# select all words from a class\n",
      "word_class = train_data[train_data[:, 3] == 1]\n",
      "word_class.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "291912"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_class.size\n",
      "len(train_vocab.keys())\n",
      "word_phat = np.zeros((len(train_vocab.keys()),2))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_counts = np.zeros((len(train_vocab.keys()),4))\n",
      "\n",
      "count = train_data[train_data[:, 1] == 1]\n",
      "print(count)\n",
      "print(count[2].sum())\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[    1     1     4     1]\n",
        " [   47     1     2     1]\n",
        " [  196     1     3     1]\n",
        " [  432     1     2     1]\n",
        " [  433     1     2     1]\n",
        " [  527     1     1     2]\n",
        " [  603     1     1     2]\n",
        " [  678     1    25     2]\n",
        " [  679     1     2     2]\n",
        " [  680     1    10     2]\n",
        " [  733     1    16     2]\n",
        " [  820     1     1     2]\n",
        " [  824     1     1     2]\n",
        " [  904     1     1     2]\n",
        " [  908     1     1     2]\n",
        " [ 1039     1     1     2]\n",
        " [ 1125     1     1     3]\n",
        " [ 1201     1     1     3]\n",
        " [ 1267     1     1     3]\n",
        " [ 1287     1     1     3]\n",
        " [ 1376     1     1     3]\n",
        " [ 1393     1     1     3]\n",
        " [ 1427     1     1     3]\n",
        " [ 1472     1     1     3]\n",
        " [ 1475     1     1     3]\n",
        " [ 1582     1     1     3]\n",
        " [ 1615     1     1     3]\n",
        " [ 1654     1     1     4]\n",
        " [ 1737     1     1     4]\n",
        " [ 1762     1     2     4]\n",
        " [ 1802     1     1     4]\n",
        " [ 1888     1     1     4]\n",
        " [ 1990     1     2     4]\n",
        " [ 2249     1     2     5]\n",
        " [ 2268     1     2     5]\n",
        " [ 2629     1     1     5]\n",
        " [ 2661     1     1     5]\n",
        " [ 2796     1     2     6]\n",
        " [ 2797     1     1     6]\n",
        " [ 2798     1     3     6]\n",
        " [ 2799     1     4     6]\n",
        " [ 2808     1     1     6]\n",
        " [ 2809     1     1     6]\n",
        " [ 2829     1     7     6]\n",
        " [ 2830     1     6     6]\n",
        " [ 2831     1     8     6]\n",
        " [ 2832     1     5     6]\n",
        " [ 2833     1     3     6]\n",
        " [ 2852     1     1     6]\n",
        " [ 2887     1     4     6]\n",
        " [ 3342     1     1     6]\n",
        " [ 4398     1     1     8]\n",
        " [ 4434     1     1     8]\n",
        " [ 4435     1     1     8]\n",
        " [ 4436     1     3     8]\n",
        " [ 4437     1     1     8]\n",
        " [ 4438     1     1     8]\n",
        " [ 4439     1     1     8]\n",
        " [ 4564     1    11     9]\n",
        " [ 4731     1     1     9]\n",
        " [ 4967     1     1     9]\n",
        " [ 5086     1     1     9]\n",
        " [ 5186     1     1    10]\n",
        " [ 5915     1     1    11]\n",
        " [ 6350     1     1    12]\n",
        " [ 6351     1     3    12]\n",
        " [ 6352     1     1    12]\n",
        " [ 6381     1     1    12]\n",
        " [ 6382     1     3    12]\n",
        " [ 6383     1    14    12]\n",
        " [ 6384     1     2    12]\n",
        " [ 6432     1     1    12]\n",
        " [ 6433     1     1    12]\n",
        " [ 6434     1     1    12]\n",
        " [ 6435     1     1    12]\n",
        " [ 6436     1     1    12]\n",
        " [ 6437     1     1    12]\n",
        " [ 6438     1     1    12]\n",
        " [ 6439     1     1    12]\n",
        " [ 6440     1     2    12]\n",
        " [ 6441     1     1    12]\n",
        " [ 6572     1     1    12]\n",
        " [ 6657     1     1    12]\n",
        " [ 6711     1     1    12]\n",
        " [ 6719     1     1    12]\n",
        " [ 6769     1     1    12]\n",
        " [ 6772     1     2    12]\n",
        " [ 6776     1     1    12]\n",
        " [ 6792     1     1    12]\n",
        " [ 6819     1     1    12]\n",
        " [ 6853     1     1    12]\n",
        " [ 6866     1     1    12]\n",
        " [ 6881     1     1    12]\n",
        " [ 6887     1     1    12]\n",
        " [ 6897     1     1    12]\n",
        " [ 6898     1     1    12]\n",
        " [ 7110     1     3    13]\n",
        " [ 7646     1     1    14]\n",
        " [ 7647     1     1    14]\n",
        " [ 7648     1     4    14]\n",
        " [ 7649     1     8    14]\n",
        " [ 8001     1     1    14]\n",
        " [ 8130     1     1    15]\n",
        " [ 8131     1     1    15]\n",
        " [ 8132     1     2    15]\n",
        " [ 8133     1     1    15]\n",
        " [ 8135     1     1    15]\n",
        " [ 8136     1     1    15]\n",
        " [ 8137     1     1    15]\n",
        " [ 8138     1     2    15]\n",
        " [ 8139     1     1    15]\n",
        " [ 8140     1     1    15]\n",
        " [ 8141     1     1    15]\n",
        " [ 8142     1     2    15]\n",
        " [ 8143     1     4    15]\n",
        " [ 8144     1     5    15]\n",
        " [ 8145     1    11    15]\n",
        " [ 8146     1     5    15]\n",
        " [ 8149     1     1    15]\n",
        " [ 8271     1     1    15]\n",
        " [ 8322     1     1    15]\n",
        " [ 8606     1     5    15]\n",
        " [ 9837     1    16    17]\n",
        " [ 9857     1     3    17]\n",
        " [ 9873     1     1    18]\n",
        " [ 9890     1     2    18]\n",
        " [ 9891     1     2    18]\n",
        " [ 9949     1     1    18]\n",
        " [10007     1     1    18]\n",
        " [10079     1     1    18]\n",
        " [10124     1     1    18]\n",
        " [10259     1     1    18]]\n",
        "201\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## May just leave this as is; no need to much too much unless i get more time\n",
      "\n",
      "word_tots = []\n",
      "countsum_words = []\n",
      "# testing on small set\n",
      "for i in range(1,10000):\n",
      "    count = train_data[train_data[:, 1] == i]\n",
      "    tot_word = count.sum(axis=0)[2]\n",
      "    word_tots.append(tot_word)\n",
      "    # print(count)\n",
      "    count_tmp = []\n",
      "    for i in range(1,21):\n",
      "        # return view over single classes\n",
      "        class_view = count[count[:,3] == i]\n",
      "        # gets scalar sum for the counts in the view\n",
      "        # and returns just that scalar value; Numpy returns an array\n",
      "        class_sum = class_view.sum(axis = 0)[2]\n",
      "        count_tmp.append(class_sum/tot_word)\n",
      "    countsum_words.append(count_tmp)\n",
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def word_counts(wordid, data):\n",
      "    count = data[data[:, 1] == wordid]\n",
      "    tot_word = count.sum(axis=0)[2]\n",
      "    return tot_word\n",
      "\n",
      "\n",
      "def word_count_help(count, data, tot_word): \n",
      "    return [(count[count[:, 3] == classid].sum(axis = 0)[2])/tot_word for classid in range(1,21)]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# word_tots = [word_counts(i, train_data) for i in range(1,1000)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tmp = [train_data[train_data[:, 1] == i].sum(axis=0)[2] for i in range(1,1000)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# word_freqs = [word_count_help(, train_data, word_tots[i-1]) for i in range(1,1000)]\n",
      "word_freqs =[]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(word_tots[50])\n",
      "print(countsum_words[50][19])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13380\n",
        "0.0446188340807\n"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_word_and_count(wordid, countsum_words, word_tots):\n",
      "    print(train_vocab[wordid])\n",
      "    print(word_tots[wordid])\n",
      "    for i in range(20):\n",
      "        print(label_map[i+1] + ': ' + str(countsum_words[wordid][i] * word_tots[wordid] ))\n",
      "        print(label_map[i+1] + ': ' + str(countsum_words[wordid][i]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_word_and_count(600, countsum_words, word_tots)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['seldes']\n",
        "167\n",
        "alt.atheism: 1.0\n",
        "alt.atheism: 0.0059880239521\n",
        "comp.graphics: 17.0\n",
        "comp.graphics: 0.101796407186\n",
        "comp.os.ms-windows.misc: 33.0\n",
        "comp.os.ms-windows.misc: 0.197604790419\n",
        "comp.sys.ibm.pc.hardware: 5.0\n",
        "comp.sys.ibm.pc.hardware: 0.0299401197605\n",
        "comp.sys.mac.hardware: 4.0\n",
        "comp.sys.mac.hardware: 0.0239520958084\n",
        "comp.windows.x: 39.0\n",
        "comp.windows.x: 0.233532934132\n",
        "misc.forsale: 2.0\n",
        "misc.forsale: 0.0119760479042\n",
        "rec.autos: 0.0\n",
        "rec.autos: 0.0\n",
        "rec.motorcycles: 3.0\n",
        "rec.motorcycles: 0.0179640718563\n",
        "rec.sport.baseball: 2.0\n",
        "rec.sport.baseball: 0.0119760479042\n",
        "rec.sport.hockey: 1.0\n",
        "rec.sport.hockey: 0.0059880239521\n",
        "sci.crypt: 8.0\n",
        "sci.crypt: 0.0479041916168\n",
        "sci.electronics: 4.0\n",
        "sci.electronics: 0.0239520958084\n",
        "sci.med: 11.0\n",
        "sci.med: 0.0658682634731\n",
        "sci.space: 6.0\n",
        "sci.space: 0.0359281437126\n",
        "soc.religion.christian: 9.0\n",
        "soc.religion.christian: 0.0538922155689\n",
        "talk.politics.guns: 10.0\n",
        "talk.politics.guns: 0.059880239521\n",
        "talk.politics.mideast: 5.0\n",
        "talk.politics.mideast: 0.0299401197605\n",
        "talk.politics.misc: 6.0\n",
        "talk.politics.misc: 0.0359281437126\n",
        "talk.religion.misc: 1.0\n",
        "talk.religion.misc: 0.0059880239521\n"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flatwords = []\n",
      "\n",
      "phat_words = np.array(countsum_words, dtype='float32')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(phat_words.shape)\n",
      "\n",
      "print(phat_words[0, :])\n",
      "print(phat_words.flags)\n",
      "print(phat_words.strides)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(9999, 20)\n",
        "[ 0.04100946  0.18927445  0.03470032  0.02523659  0.01892745  0.14826499\n",
        "  0.          0.02839117  0.04416404  0.00315457  0.00315457  0.16403785\n",
        "  0.00946372  0.04731861  0.15141957  0.          0.05993691  0.03154574\n",
        "  0.          0.        ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  C_CONTIGUOUS : True\n",
        "  F_CONTIGUOUS : False\n",
        "  OWNDATA : True\n",
        "  WRITEABLE : True\n",
        "  ALIGNED : True\n",
        "  UPDATEIFCOPY : False\n",
        "(80, 4)\n"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def printmaxclass(phat_words, wordid, vocab):\n",
      "    # print(phat_words[0, :])\n",
      "    maxindex = phat_words[wordid, :].argmax()\n",
      "    print(str(vocab[maxindex]) + \": \" + str(phat_words[wordid, maxindex]) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "printmaxclass(phat_words, 1, train_vocab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['alt']: 0.162757\n"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}