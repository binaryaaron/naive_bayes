{
 "metadata": {
  "name": "",
  "signature": "sha256:0cad4c6bf792a2cf830768e20e44d5f449ef54387d36e61b5877b69a18f6aa66"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import utils as utils\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import csv\n",
      "from pprint import pprint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train data is a preprocessed file\n",
      "train_data = np.loadtxt('../data/train.full', dtype='uint16', )\n",
      "train_vocab = utils.read_file_dict('../data/vocabulary.txt')\n",
      "label_map = utils.read_mapfile('../data/train.map')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "20"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "(1467345, 4)"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_prior = {}\n",
      "vec = train_data[:,3]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(1,21):\n",
      "    view = vec[vec == i]\n",
      "    train_prior[label_map[i]] = view.size/vec.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(train_data.size)\n",
      "pprint(train_prior)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5869380\n",
        "{'alt.atheism': 0.04973472496243215,\n",
        " 'comp.graphics': 0.03984884263755286,\n",
        " 'comp.os.ms-windows.misc': 0.03736203823913258,\n",
        " 'comp.sys.ibm.pc.hardware': 0.03930364024820339,\n",
        " 'comp.sys.mac.hardware': 0.03619734963488477,\n",
        " 'comp.windows.x': 0.04659572220575257,\n",
        " 'misc.forsale': 0.028811220265172813,\n",
        " 'rec.autos': 0.04723224599531808,\n",
        " 'rec.motorcycles': 0.045334941680381914,\n",
        " 'rec.sport.baseball': 0.044625497071240916,\n",
        " 'rec.sport.hockey': 0.0525384282496618,\n",
        " 'sci.crypt': 0.06796152234137166,\n",
        " 'sci.electronics': 0.041876995525932895,\n",
        " 'sci.med': 0.058204444080976185,\n",
        " 'sci.space': 0.057467739352367715,\n",
        " 'soc.religion.christian': 0.06856397098160283,\n",
        " 'talk.politics.guns': 0.06309968003434775,\n",
        " 'talk.politics.mideast': 0.0772333704752461,\n",
        " 'talk.politics.misc': 0.05740981159849933,\n",
        " 'talk.religion.misc': 0.0405978144199217}\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_priors = utils.estimate_priors(label_map, vec)\n",
      "pprint(train_priors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'alt.atheism': 0.04973472496243215,\n",
        " 'comp.graphics': 0.03984884263755286,\n",
        " 'comp.os.ms-windows.misc': 0.03736203823913258,\n",
        " 'comp.sys.ibm.pc.hardware': 0.03930364024820339,\n",
        " 'comp.sys.mac.hardware': 0.03619734963488477,\n",
        " 'comp.windows.x': 0.04659572220575257,\n",
        " 'misc.forsale': 0.028811220265172813,\n",
        " 'rec.autos': 0.04723224599531808,\n",
        " 'rec.motorcycles': 0.045334941680381914,\n",
        " 'rec.sport.baseball': 0.044625497071240916,\n",
        " 'rec.sport.hockey': 0.0525384282496618,\n",
        " 'sci.crypt': 0.06796152234137166,\n",
        " 'sci.electronics': 0.041876995525932895,\n",
        " 'sci.med': 0.058204444080976185,\n",
        " 'sci.space': 0.057467739352367715,\n",
        " 'soc.religion.christian': 0.06856397098160283,\n",
        " 'talk.politics.guns': 0.06309968003434775,\n",
        " 'talk.politics.mideast': 0.0772333704752461,\n",
        " 'talk.politics.misc': 0.05740981159849933,\n",
        " 'talk.religion.misc': 0.0405978144199217}\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vec.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "(1467345,)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = train_data[train_data[:, 0] == 900]\n",
      "d = train_data[train_data[:, 0] == 1010]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t.size\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "128"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "440"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this doc is weird\n",
      "words_from = utils.get_words_from_doc(9946, train_data, train_vocab)\n",
      "print(words_from)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['last', 'of', 'from', 'and', 'other', 'are', 'the', 'in', 'us', 'to', 'it', 'like', 'on', 'their', 'but', 'with', 'written', 'is', 'people', 'can', 'try', 'com', 'for', 'who', 'go', 'price', 'so', 'one', 'such', 'by', 'or', 'an', 'may', 'be', 'older', 'they', 'south', 'place', 'that', 'all', 'any', 'well', 'this', 'lives', 'set', 'at', 'very', 'about', 'truth', 'rather', 'than', 'often', 'some', 'women', 'remote', 'demand', 'death', 'its', 'after', 'reality', 'into', 'young', 'as', 'right', 'under', 'own', 'only', 'old', 'first', 'more', 'work', 'has', 'if', 'you', 'know', 'what', 'make', 'sure', 'seems', 'even', 'etc', 'die', 'great', 'most', 'case', 'against', 'comprehensive', 'best', 'way', 'view', 'kind', 'statements', 'men', 'was', 'were', 'moral', 'those', 'concept', 'better', 'hand', 'murder', 'not', 'there', 'small', 'information', 'will', 'back', 'article', 'writes', 'answering', 'our', 'questions', 'question', 'could', 'resulted', 'we', 'did', 'these', 'just', 'much', 'nothing', 'me', 'do', 'called', 'no', 'since', 'deal', 'up', 'yes', 'now', 'have', 'little', 'asking', 'should', 'end', 'killing', 'innocent', 'your', 'claim', 'wrong', 'want', 'fine', 'every', 'am', 'between', 'say', 'my', 'would', 'answer', 'before', 'where', 'years', 'specifically', 'too', 'until', 'going', 'killed', 'result', 'kill', 'taking', 'situation', 'either', 'myself', 'bit', 'usually', 'solely', 'necessary', 'similar', 'really', 'once', 'irrelevant', 'concerned', 'blood', 'others', 'members', 'accept', 'circumstances', 'time', 'issue', 'though', 'able', 'yourself', 'fact', 'free', 'matter', 'opinion', 're', 'allow', 'cannot', 'important', 'realize', 'hope', 'maybe', 'along', 'ask', 'agree', 'interested', 'bad', 'problem', 'act', 'real', 'attacks', 'occurs', 'consider', 'cold', 'come', 'policy', 'feel', 'telling', 'basis', 'far', 'home', 'imagine', 'caused', 'troops', 'happened', 'apr', 'give', 'strikes', 'thread', 'removal', 'hard', 'government', 'already', 'figure', 'talks', 'soldiers', 'fields', 'jews', 'failed', 'stop', 'supported', 'accurate', 'conclusion', 'pay', 'year', 'public', 'finding', 'force', 'responsible', 'newsgroup', 'advance', 'attacked', 'bunch', 'controlling', 'business', 'heavy', 'save', 'nobody', 'wants', 'comments', 'coffee', 'drink', 'hold', 'pressure', 'ignorant', 'peace', 'candidate', 'proven', 'cities', 'whereby', 'communities', 'terrorism', 'deaths', 'side', 'knows', 'three', 'compare', 'solution', 'playing', 'image', 'shell', 'parts', 'occasional', 'protection', 'ground', 'proper', 'hearted', 'efforts', 'addressed', 'kids', 'summer', 'camp', 'streets', 'militarily', 'unilaterally', 'move', 'israel', 'girl', 'protect', 'picture', 'capable', 'land', 'israeli', 'offered', 'iran', 'camps', 'borders', 'keeping', 'bomb', 'protecting', 'feeling', 'announce', 'daily', 'st', 'warn', 'quarrel', 'hurt', 'cards', 'gonna', 'resistance', 'occupation', 'civilians', 'attacking', 'terrorist', 'exercise', 'qualified', 'incentive', 'filled', 'bombs', 'security', 'choosing', 'civilian', 'bombing', 'bombed', 'lift', 'suspect', 'receiving', 'injured', 'lunch', 'insists', 'regular', 'aimed', 'northern', 'misinformation', 'southern', 'border', 'buffer', 'colored', 'unocal', 'edge', 'heavily', 'paint', 'arms', 'realistic', 'rightly', 'establishment', 'toll', 'genuinely', 'shop', 'preparing', 'soccer', 'traps', 'munich', 'zone', 'occupied', 'shops', 'insure', 'hurting', 'village', 'brave', 'soldier', 'aged', 'tactics', 'eliminating', 'pilots', 'condone', 'justifies', 'patrol', 'accustomed', 'financially', 'settlement', 'leverage', 'athletes', 'secretive', 'withdraw', 'sneak', 'shelled', 'concessions', 'basil', 'terrorists', 'abroad', 'disarmed', 'withdrawal', 'militias', 'disarming', 'inhabitants', 'occupying', 'indiscriminate', 'lebanon', 'diverting', 'stationed', 'villages', 'indiscriminately', 'ammunitions', 'israelis', 'dorin', 'stssdxb', 'baru', 'negociations', 'syrian', 'lebanese', 'shelling', 'iraelis', 'booby', 'terrritory', 'disingeneous', 'mrder', 'coffe', 'patrols', 'retalliates', 'hideout', 'villagers', 'retalliation', 'withdraws', 'hizbollah', 'goovernment', 'isareli']\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "MLE for $P(Y_k)$\n",
      "$$P(Y_k) = \\frac{\\#\\ of\\ docs\\ labeled\\ Y_k}{total\\ \\#\\ of\\ docs}$$\n",
      "\n",
      "\n",
      "MAP for $P(X_i|Y_k)$\n",
      "\n",
      "$$P(X_i|Y_k) = \\frac{(count\\ of\\ X_i\\ in\\ Y_k)+(\\alpha -1)}{(total\\ words\\ in Y_k)+((\\alpha - 1)*(length\\ of\\ vocab\\ list)))}$$\n",
      "\n",
      "Where \n",
      "$\\alpha = 1 + \\beta$\n",
      "\n",
      "and\n",
      "$\\beta = \\frac{1}{|V|}$\n",
      "\n",
      "And classify\n",
      "$$Y^{new} = argmax \\big[\\ log_2(P(Y_k)) + \\sum_{i}(\\#\\ of\\ X^{new}_i)log_2(P(X_i|Y_k))\\big]$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Possibly make a new numpy array for d's priors\n",
      "\n",
      " docid |class | c_1 ... c_20  \n",
      "-------|------|----------------\n",
      " 1     |  2   | 0.1 \n",
      " \n",
      " And one for words:\n",
      " \n",
      "  wordid |class | p_hat\n",
      "-------|------|----------------\n",
      " 1     |  1   | 0.1\n",
      " 1     |  2   | 0.02\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# select all words from a class\n",
      "word_class = train_data[train_data[:, 3] == 1]\n",
      "word_class.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "291912"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_class.size\n",
      "len(train_vocab.keys())\n",
      "word_phat = np.zeros((len(train_vocab.keys()),2))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_counts = np.zeros((len(train_vocab.keys()),4))\n",
      "\n",
      "count = train_data[train_data[:, 1] == 40]\n",
      "print(count)\n",
      "print(count[:,2].sum())\n",
      "print(count.sum(axis=0)[2])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[    1    40     3     1]\n",
        " [  679    40     1     2]\n",
        " [ 1180    40     1     3]\n",
        " [ 1470    40     1     3]\n",
        " [ 1617    40     1     3]\n",
        " [ 1656    40     1     4]\n",
        " [ 1724    40     1     4]\n",
        " [ 1801    40     1     4]\n",
        " [ 1956    40     1     4]\n",
        " [ 2304    40     1     5]\n",
        " [ 2320    40     1     5]\n",
        " [ 2752    40     4     5]\n",
        " [ 2829    40     1     6]\n",
        " [ 3627    40     2     7]\n",
        " [ 3648    40     1     7]\n",
        " [ 3749    40     1     7]\n",
        " [ 4438    40     2     8]\n",
        " [ 4456    40     1     8]\n",
        " [ 4466    40     1     8]\n",
        " [ 5781    40     1    11]\n",
        " [ 5971    40     1    11]\n",
        " [ 6184    40     1    11]\n",
        " [ 6572    40     1    12]\n",
        " [ 6657    40     2    12]\n",
        " [ 6868    40     1    12]\n",
        " [ 6906    40     1    12]\n",
        " [ 6955    40     2    13]\n",
        " [ 6993    40     1    13]\n",
        " [ 7172    40     1    13]\n",
        " [ 7202    40     1    13]\n",
        " [ 7205    40     1    13]\n",
        " [ 7286    40     1    13]\n",
        " [ 7292    40     1    13]\n",
        " [ 7787    40     1    14]\n",
        " [ 7849    40     1    14]\n",
        " [ 8187    40     1    15]\n",
        " [ 8237    40     3    15]\n",
        " [ 8343    40     1    15]\n",
        " [ 8430    40     1    15]\n",
        " [ 8638    40     2    15]\n",
        " [ 8646    40     1    15]\n",
        " [ 8712    40     1    15]\n",
        " [ 9339    40     1    17]\n",
        " [ 9441    40     1    17]\n",
        " [ 9465    40     1    17]\n",
        " [ 9501    40     1    17]\n",
        " [10029    40     1    18]\n",
        " [10037    40     1    18]\n",
        " [10121    40     1    18]\n",
        " [10201    40     1    18]\n",
        " [10613    40     1    19]]\n",
        "63\n",
        "63\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_tots = np.zeros((1, len(train_vocab)), dtype='int32')\n",
      "countsum_words = np.zeros((1, len(train_vocab)*20), dtype='float32')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = np.zeros( (len(train_vocab), 21), dtype='float32')\n",
      "print(test.strides)\n",
      "print(test.shape)\n",
      "print(test.flags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(84, 4)\n",
        "(61188, 21)\n",
        "  C_CONTIGUOUS : True\n",
        "  F_CONTIGUOUS : False\n",
        "  OWNDATA : True\n",
        "  WRITEABLE : True\n",
        "  ALIGNED : True\n",
        "  UPDATEIFCOPY : False\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[i for i in range(1,10)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# testing on small set; going to use numpy\n",
      "for i in range(1,len(train_vocab)+1):\n",
      "    count = train_data[train_data[:, 1] == i]\n",
      "    #tot_word = count.sum(axis=0)[2]\n",
      "    test[i-1, 0] = count[:,2].sum()\n",
      "    # word_tots.append(tot_word)\n",
      "    # print(count)\n",
      "   # count_tmp = []\n",
      "    for j in range(1,21):\n",
      "        # return view over single classes\n",
      "        class_view = count[count[:,3] == j]\n",
      "        # gets scalar sum for the counts in the view\n",
      "        # and returns just that scalar value; Numpy returns an array\n",
      "        # class_sum = class_view[:,2].sum(axis = 0)\n",
      "        #count_tmp.append(class_sum/tot_word)\n",
      "        # test[i-1, j] = (class_sum/test[i-1,0])\n",
      "        test[i-1, j] = class_view[:, 2].sum()\n",
      "        \n",
      "    # countsum_words.append(count_tmp)\n",
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newmat = np.zeros((len(train_vocab), 21), dtype='float32')\n",
      "\n",
      "for i in range(0,21):\n",
      "    newmat[:,i-1] = test[:,i+1] / test[:,0] \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "index 21 is out of bounds for axis 1 with size 21",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-80-69ba46ed8656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnewmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mIndexError\u001b[0m: index 21 is out of bounds for axis 1 with size 21"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(newmat[100,])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.03795202  0.01897601  0.02327247  0.02291443  0.04368063  0.00716076\n",
        "  0.02900107  0.02398854  0.01432152  0.01074114  0.11528822  0.02685285\n",
        "  0.07017544  0.06480487  0.07984246  0.07053348  0.12316506  0.07017544\n",
        "  0.06086645  0.          0.08628715]\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_word_and_count(wordid):\n",
      "    print(train_vocab[wordid])\n",
      "    print(word_tots[wordid])\n",
      "    for i in range(1, 20):\n",
      "        print(label_map[i] + ': ' + str(countsum_words[wordid][i] * word_tots[wordid] ))\n",
      "        print(label_map[i] + ': ' + str(countsum_words[wordid][i]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_word_and_count(6000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['stuart']\n",
        "11\n",
        "alt.atheism: 1.0\n",
        "alt.atheism: 0.0909090909091\n",
        "comp.graphics: 1.0\n",
        "comp.graphics: 0.0909090909091\n",
        "comp.os.ms-windows.misc: 0.0\n",
        "comp.os.ms-windows.misc: 0.0\n",
        "comp.sys.ibm.pc.hardware: 0.0\n",
        "comp.sys.ibm.pc.hardware: 0.0\n",
        "comp.sys.mac.hardware: 3.0\n",
        "comp.sys.mac.hardware: 0.272727272727\n",
        "comp.windows.x: 2.0\n",
        "comp.windows.x: 0.181818181818\n",
        "misc.forsale: 2.0\n",
        "misc.forsale: 0.181818181818\n",
        "rec.autos: 0.0\n",
        "rec.autos: 0.0\n",
        "rec.motorcycles: 0.0\n",
        "rec.motorcycles: 0.0\n",
        "rec.sport.baseball: 0.0\n",
        "rec.sport.baseball: 0.0\n",
        "rec.sport.hockey: 0.0\n",
        "rec.sport.hockey: 0.0\n",
        "sci.crypt: 0.0\n",
        "sci.crypt: 0.0\n",
        "sci.electronics: 0.0\n",
        "sci.electronics: 0.0\n",
        "sci.med: 1.0\n",
        "sci.med: 0.0909090909091\n",
        "sci.space: 0.0\n",
        "sci.space: 0.0\n",
        "soc.religion.christian: 0.0\n",
        "soc.religion.christian: 0.0\n",
        "talk.politics.guns: 0.0\n",
        "talk.politics.guns: 0.0\n",
        "talk.politics.mideast: 0.0\n",
        "talk.politics.mideast: 0.0\n",
        "talk.politics.misc: 0.0\n",
        "talk.politics.misc: 0.0\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flatwords = []\n",
      "\n",
      "from scipy.sparse import csc_matrix\n",
      "phat_words = csc_matrix(test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(phat_words * 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 0)\t31700.0\n",
        "  (1, 0)\t136400.0\n",
        "  (2, 0)\t30000.0\n",
        "  (3, 0)\t22600.0\n",
        "  (4, 0)\t32700.0\n",
        "  (5, 0)\t183200.0\n",
        "  (6, 0)\t12500.0\n",
        "  (7, 0)\t10800.0\n",
        "  (8, 0)\t100200.0\n",
        "  (9, 0)\t20800.0\n",
        "  (10, 0)\t14200.0\n",
        "  (11, 0)\t6.417e+06\n",
        "  (12, 0)\t17800.0\n",
        "  (13, 0)\t46100.0\n",
        "  (14, 0)\t34100.0\n",
        "  (15, 0)\t1.1109e+06\n",
        "  (16, 0)\t60900.0\n",
        "  (17, 0)\t15200.0\n",
        "  (18, 0)\t2000.0\n",
        "  (19, 0)\t6400.0\n",
        "  (20, 0)\t3500.0\n",
        "  (21, 0)\t2100.0\n",
        "  (22, 0)\t5.6701e+06\n",
        "  (23, 0)\t1300.0\n",
        "  (24, 0)\t513400.0\n",
        "  :\t:\n",
        "  (61163, 20)\tnan\n",
        "  (61164, 20)\tnan\n",
        "  (61165, 20)\tnan\n",
        "  (61166, 20)\tnan\n",
        "  (61167, 20)\tnan\n",
        "  (61168, 20)\tnan\n",
        "  (61169, 20)\tnan\n",
        "  (61170, 20)\tnan\n",
        "  (61171, 20)\tnan\n",
        "  (61172, 20)\tnan\n",
        "  (61173, 20)\tnan\n",
        "  (61174, 20)\tnan\n",
        "  (61175, 20)\tnan\n",
        "  (61176, 20)\tnan\n",
        "  (61177, 20)\tnan\n",
        "  (61178, 20)\tnan\n",
        "  (61179, 20)\tnan\n",
        "  (61180, 20)\tnan\n",
        "  (61181, 20)\tnan\n",
        "  (61182, 20)\tnan\n",
        "  (61183, 20)\tnan\n",
        "  (61184, 20)\tnan\n",
        "  (61185, 20)\tnan\n",
        "  (61186, 20)\tnan\n",
        "  (61187, 20)\tnan\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(phat_words.shape)\n",
      "\n",
      "\n",
      "print(phat_words[0, :])\n",
      "print(phat_words.flags)\n",
      "print(phat_words.strides)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'phat_words' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-23-889b88cbcb0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphat_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphat_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphat_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'phat_words' is not defined"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def printmaxclass(phat_words, wordid, vocab):\n",
      "    # print(phat_words[0, :])\n",
      "    maxindex = phat_words[wordid, :].argmax()\n",
      "    print(str(vocab[maxindex]) + \": \" + str(phat_words[wordid, maxindex]) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "printmaxclass(phat_words, 1, train_vocab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['alt']: 0.162757\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}