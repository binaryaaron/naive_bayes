{
 "metadata": {
  "name": "",
  "signature": "sha256:c1939fb98014e1e2af79da6c2115044b12393c60080e17cd907cc079f87148ab"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "%load_ext autoreload\n",
      "%autoreload 1\n",
      "%aimport bayes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twenty_train = fetch_20newsgroups(subset='train',\n",
      "                                  remove=('headers', 'footers', 'quotes'),\n",
      "                                  shuffle=True, random_state=42)\n",
      "twenty_test = fetch_20newsgroups(subset='test',\n",
      "                                  remove=('headers', 'footers', 'quotes'),\n",
      "                                  shuffle=True, random_state=42)\n",
      "\n",
      "twenty_train.target_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "['alt.atheism',\n",
        " 'comp.graphics',\n",
        " 'comp.os.ms-windows.misc',\n",
        " 'comp.sys.ibm.pc.hardware',\n",
        " 'comp.sys.mac.hardware',\n",
        " 'comp.windows.x',\n",
        " 'misc.forsale',\n",
        " 'rec.autos',\n",
        " 'rec.motorcycles',\n",
        " 'rec.sport.baseball',\n",
        " 'rec.sport.hockey',\n",
        " 'sci.crypt',\n",
        " 'sci.electronics',\n",
        " 'sci.med',\n",
        " 'sci.space',\n",
        " 'soc.religion.christian',\n",
        " 'talk.politics.guns',\n",
        " 'talk.politics.mideast',\n",
        " 'talk.politics.misc',\n",
        " 'talk.religion.misc']"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(twenty_train.target[500])\n",
      "print(twenty_train.data[500])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n",
        "\n",
        "I got one from Microsoft tech support.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fit bag of words model to the dataset with specified params\n",
      "cv_train = CountVectorizer(stop_words='english',\n",
      "                     max_df=.95,\n",
      "                     min_df=0.001,\n",
      "                     strip_accents='unicode'\n",
      "                     )\n",
      "bow_train = cv_train.fit_transform(twenty_train.data)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_test = CountVectorizer(stop_words='english',\n",
      "                     max_df=.95,\n",
      "                     min_df=0.001,\n",
      "                     strip_accents='unicode',\n",
      "                     vocabulary=cv_train.vocabulary_\n",
      "                     )\n",
      "bow_test = cv_test.fit_transform(twenty_test.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(bow_train.shape)\n",
      "print(bow_test.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(11314, 9053)\n",
        "(7532, 9053)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(bow_test.shape)\n",
      "print(twenty_test.data[0])\n",
      "print(len(twenty_test.data[0].strip().split()))\n",
      "\n",
      "\n",
      "print(bow_test[0, :].toarray())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7532, 9053)\n",
        "I am a little confused on all of the models of the 88-89 bonnevilles.\n",
        "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
        "differences are far as features or performance. I am also curious to\n",
        "know what the book value is for prefereably the 89 model. And how much\n",
        "less than book value can you usually get them for. In other words how\n",
        "much are they in demand this time of year. I have heard that the mid-spring\n",
        "early summer is the best time to buy.\n",
        "92\n",
        "[[0 0 0 ..., 0 0 0]]\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_test.get_stop_words()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "frozenset({'a',\n",
        "           'about',\n",
        "           'above',\n",
        "           'across',\n",
        "           'after',\n",
        "           'afterwards',\n",
        "           'again',\n",
        "           'against',\n",
        "           'all',\n",
        "           'almost',\n",
        "           'alone',\n",
        "           'along',\n",
        "           'already',\n",
        "           'also',\n",
        "           'although',\n",
        "           'always',\n",
        "           'am',\n",
        "           'among',\n",
        "           'amongst',\n",
        "           'amoungst',\n",
        "           'amount',\n",
        "           'an',\n",
        "           'and',\n",
        "           'another',\n",
        "           'any',\n",
        "           'anyhow',\n",
        "           'anyone',\n",
        "           'anything',\n",
        "           'anyway',\n",
        "           'anywhere',\n",
        "           'are',\n",
        "           'around',\n",
        "           'as',\n",
        "           'at',\n",
        "           'back',\n",
        "           'be',\n",
        "           'became',\n",
        "           'because',\n",
        "           'become',\n",
        "           'becomes',\n",
        "           'becoming',\n",
        "           'been',\n",
        "           'before',\n",
        "           'beforehand',\n",
        "           'behind',\n",
        "           'being',\n",
        "           'below',\n",
        "           'beside',\n",
        "           'besides',\n",
        "           'between',\n",
        "           'beyond',\n",
        "           'bill',\n",
        "           'both',\n",
        "           'bottom',\n",
        "           'but',\n",
        "           'by',\n",
        "           'call',\n",
        "           'can',\n",
        "           'cannot',\n",
        "           'cant',\n",
        "           'co',\n",
        "           'con',\n",
        "           'could',\n",
        "           'couldnt',\n",
        "           'cry',\n",
        "           'de',\n",
        "           'describe',\n",
        "           'detail',\n",
        "           'do',\n",
        "           'done',\n",
        "           'down',\n",
        "           'due',\n",
        "           'during',\n",
        "           'each',\n",
        "           'eg',\n",
        "           'eight',\n",
        "           'either',\n",
        "           'eleven',\n",
        "           'else',\n",
        "           'elsewhere',\n",
        "           'empty',\n",
        "           'enough',\n",
        "           'etc',\n",
        "           'even',\n",
        "           'ever',\n",
        "           'every',\n",
        "           'everyone',\n",
        "           'everything',\n",
        "           'everywhere',\n",
        "           'except',\n",
        "           'few',\n",
        "           'fifteen',\n",
        "           'fify',\n",
        "           'fill',\n",
        "           'find',\n",
        "           'fire',\n",
        "           'first',\n",
        "           'five',\n",
        "           'for',\n",
        "           'former',\n",
        "           'formerly',\n",
        "           'forty',\n",
        "           'found',\n",
        "           'four',\n",
        "           'from',\n",
        "           'front',\n",
        "           'full',\n",
        "           'further',\n",
        "           'get',\n",
        "           'give',\n",
        "           'go',\n",
        "           'had',\n",
        "           'has',\n",
        "           'hasnt',\n",
        "           'have',\n",
        "           'he',\n",
        "           'hence',\n",
        "           'her',\n",
        "           'here',\n",
        "           'hereafter',\n",
        "           'hereby',\n",
        "           'herein',\n",
        "           'hereupon',\n",
        "           'hers',\n",
        "           'herself',\n",
        "           'him',\n",
        "           'himself',\n",
        "           'his',\n",
        "           'how',\n",
        "           'however',\n",
        "           'hundred',\n",
        "           'i',\n",
        "           'ie',\n",
        "           'if',\n",
        "           'in',\n",
        "           'inc',\n",
        "           'indeed',\n",
        "           'interest',\n",
        "           'into',\n",
        "           'is',\n",
        "           'it',\n",
        "           'its',\n",
        "           'itself',\n",
        "           'keep',\n",
        "           'last',\n",
        "           'latter',\n",
        "           'latterly',\n",
        "           'least',\n",
        "           'less',\n",
        "           'ltd',\n",
        "           'made',\n",
        "           'many',\n",
        "           'may',\n",
        "           'me',\n",
        "           'meanwhile',\n",
        "           'might',\n",
        "           'mill',\n",
        "           'mine',\n",
        "           'more',\n",
        "           'moreover',\n",
        "           'most',\n",
        "           'mostly',\n",
        "           'move',\n",
        "           'much',\n",
        "           'must',\n",
        "           'my',\n",
        "           'myself',\n",
        "           'name',\n",
        "           'namely',\n",
        "           'neither',\n",
        "           'never',\n",
        "           'nevertheless',\n",
        "           'next',\n",
        "           'nine',\n",
        "           'no',\n",
        "           'nobody',\n",
        "           'none',\n",
        "           'noone',\n",
        "           'nor',\n",
        "           'not',\n",
        "           'nothing',\n",
        "           'now',\n",
        "           'nowhere',\n",
        "           'of',\n",
        "           'off',\n",
        "           'often',\n",
        "           'on',\n",
        "           'once',\n",
        "           'one',\n",
        "           'only',\n",
        "           'onto',\n",
        "           'or',\n",
        "           'other',\n",
        "           'others',\n",
        "           'otherwise',\n",
        "           'our',\n",
        "           'ours',\n",
        "           'ourselves',\n",
        "           'out',\n",
        "           'over',\n",
        "           'own',\n",
        "           'part',\n",
        "           'per',\n",
        "           'perhaps',\n",
        "           'please',\n",
        "           'put',\n",
        "           'rather',\n",
        "           're',\n",
        "           'same',\n",
        "           'see',\n",
        "           'seem',\n",
        "           'seemed',\n",
        "           'seeming',\n",
        "           'seems',\n",
        "           'serious',\n",
        "           'several',\n",
        "           'she',\n",
        "           'should',\n",
        "           'show',\n",
        "           'side',\n",
        "           'since',\n",
        "           'sincere',\n",
        "           'six',\n",
        "           'sixty',\n",
        "           'so',\n",
        "           'some',\n",
        "           'somehow',\n",
        "           'someone',\n",
        "           'something',\n",
        "           'sometime',\n",
        "           'sometimes',\n",
        "           'somewhere',\n",
        "           'still',\n",
        "           'such',\n",
        "           'system',\n",
        "           'take',\n",
        "           'ten',\n",
        "           'than',\n",
        "           'that',\n",
        "           'the',\n",
        "           'their',\n",
        "           'them',\n",
        "           'themselves',\n",
        "           'then',\n",
        "           'thence',\n",
        "           'there',\n",
        "           'thereafter',\n",
        "           'thereby',\n",
        "           'therefore',\n",
        "           'therein',\n",
        "           'thereupon',\n",
        "           'these',\n",
        "           'they',\n",
        "           'thick',\n",
        "           'thin',\n",
        "           'third',\n",
        "           'this',\n",
        "           'those',\n",
        "           'though',\n",
        "           'three',\n",
        "           'through',\n",
        "           'throughout',\n",
        "           'thru',\n",
        "           'thus',\n",
        "           'to',\n",
        "           'together',\n",
        "           'too',\n",
        "           'top',\n",
        "           'toward',\n",
        "           'towards',\n",
        "           'twelve',\n",
        "           'twenty',\n",
        "           'two',\n",
        "           'un',\n",
        "           'under',\n",
        "           'until',\n",
        "           'up',\n",
        "           'upon',\n",
        "           'us',\n",
        "           'very',\n",
        "           'via',\n",
        "           'was',\n",
        "           'we',\n",
        "           'well',\n",
        "           'were',\n",
        "           'what',\n",
        "           'whatever',\n",
        "           'when',\n",
        "           'whence',\n",
        "           'whenever',\n",
        "           'where',\n",
        "           'whereafter',\n",
        "           'whereas',\n",
        "           'whereby',\n",
        "           'wherein',\n",
        "           'whereupon',\n",
        "           'wherever',\n",
        "           'whether',\n",
        "           'which',\n",
        "           'while',\n",
        "           'whither',\n",
        "           'who',\n",
        "           'whoever',\n",
        "           'whole',\n",
        "           'whom',\n",
        "           'whose',\n",
        "           'why',\n",
        "           'will',\n",
        "           'with',\n",
        "           'within',\n",
        "           'without',\n",
        "           'would',\n",
        "           'yet',\n",
        "           'you',\n",
        "           'your',\n",
        "           'yours',\n",
        "           'yourself',\n",
        "           'yourselves'})"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# count for document 500\n",
      "print(bow_train[500])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 3810)\t1\n",
        "  (0, 8104)\t1\n",
        "  (0, 7966)\t1\n",
        "  (0, 5286)\t1\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twenty_train.target.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "11314"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# testing prior class probs\n",
      "view = twenty_train.target[twenty_train.target == 0]\n",
      "print(view.size/twenty_train.target.size)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.04242531377054976\n"
       ]
      }
     ],
     "prompt_number": 347
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# old funct to get priors\n",
      "class_priors = np.zeros(shape=(20,), dtype='float64')\n",
      "\n",
      "for idx, lab in enumerate(twenty_train.target_names):\n",
      "    view = twenty_train.target[twenty_train.target == idx]\n",
      "    class_priors[idx] = view.size/twenty_train.target.size\n",
      "    print(lab + ' ' + str(class_priors[idx]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "alt.atheism 0.0424253\n",
        "comp.graphics 0.0516175\n",
        "comp.os.ms-windows.misc 0.0522362\n",
        "comp.sys.ibm.pc.hardware 0.0521478\n",
        "comp.sys.mac.hardware 0.0510871\n",
        "comp.windows.x 0.0524129\n",
        "misc.forsale 0.0517059\n",
        "rec.autos 0.0525013\n",
        "rec.motorcycles 0.0528549\n",
        "rec.sport.baseball 0.0527665\n",
        "rec.sport.hockey 0.0530316\n",
        "sci.crypt 0.0525897\n",
        "sci.electronics 0.0522362\n",
        "sci.med 0.0525013\n",
        "sci.space 0.0524129\n",
        "soc.religion.christian 0.0529433\n",
        "talk.politics.guns 0.0482588\n",
        "talk.politics.mideast 0.0498497\n",
        "talk.politics.misc 0.0410995\n",
        "talk.religion.misc 0.0333215\n"
       ]
      }
     ],
     "prompt_number": 348
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class_priors = bayes.phat_class_est(twenty_train.target, twenty_train.target_names, debug=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Estimating prior class probabilities\n",
        "alt.atheism: 0.0424253137705\n",
        "comp.graphics: 0.0516174650875\n",
        "comp.os.ms-windows.misc: 0.05223616758\n",
        "comp.sys.ibm.pc.hardware: 0.0521477815096\n",
        "comp.sys.mac.hardware: 0.0510871486654\n",
        "comp.windows.x: 0.0524129397207\n",
        "misc.forsale: 0.0517058511579\n",
        "rec.autos: 0.0525013257911\n",
        "rec.motorcycles: 0.0528548700725\n",
        "rec.sport.baseball: 0.0527664840021\n",
        "rec.sport.hockey: 0.0530316422132\n",
        "sci.crypt: 0.0525897118614\n",
        "sci.electronics: 0.05223616758\n",
        "sci.med: 0.0525013257911\n",
        "sci.space: 0.0524129397207\n",
        "soc.religion.christian: 0.0529432561428\n",
        "talk.politics.guns: 0.048258794414\n",
        "talk.politics.mideast: 0.0498497436804\n",
        "talk.politics.misc: 0.0410995227152\n",
        "talk.religion.misc: 0.033321548524\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.where(class_priors > 0.05, 4, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array([0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.unique(bow_train[:,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "array([ <11314x1 sparse matrix of type '<class 'numpy.int64'>'\n",
        "\twith 262 stored elements in Compressed Sparse Row format>], dtype=object)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = bow_train[:,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "1204"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this sums all the columns in the sparse matrix into a resulting vector\n",
      "word_sums = bow_train.sum(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class_mask1 = twenty_train.target == 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csums = bow_train[class_mask1].sum(axis=0) + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## okay, now put it together for maximum likelihood\n",
      "\n",
      "## preallocate array, 20 row, word dic length\n",
      "phat_words = np.zeros((20, bow_train.shape[1]), dtype='float64')\n",
      "\n",
      "## create sum vectors and assign them to the correct spot\n",
      "## may need to fiddle with smoothing params\n",
      "for idx, lab in enumerate(twenty_train.target_names):\n",
      "    c_mask = twenty_train.target == idx\n",
      "    c_sum = bow_train[c_mask].sum(axis=0)\n",
      "    c_sum = c_sum + 1\n",
      "    # print(c_sum/word_sums)\n",
      "    phat_words[idx] = (c_sum / (word_sums + 20))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(phat_words[10] > 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "9053"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phat_words = bayes.phat_word_est(bow_train, class_labels=twenty_train.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "estimating params with Dirchlet Prior:\n",
        "\t vocabsize = 11314.000000\n",
        "\t beta = 0.000088\n",
        "\t alpha = 1.000088\n",
        "\t denominator = 1.000000\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(phat_words[:,0])\n",
      "print(phat_words.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  7.33494360e-08   2.15768368e-02   1.49378327e-02   1.65975837e-02\n",
        "   5.80920198e-03   5.97511107e-02   5.12033268e-01   1.41079572e-02\n",
        "   6.63907750e-03   1.45228289e-01   9.12863804e-02   9.95857957e-03\n",
        "   1.32780816e-02   1.82573348e-02   2.65560899e-02   4.14945094e-03\n",
        "   1.99170858e-02   5.80920198e-03   1.24482061e-02   8.29948868e-04]\n",
        "(20, 9053)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this is a sanity check; all should sum to one\n",
      "c_map = np.sum(phat_words, axis=0)\n",
      "print(c_map.shape)\n",
      "print(c_map)\n",
      "# number of elements above a threshold\n",
      "np.sum(np.where(c_map > 0.99, 1, 0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(9053,)\n",
        "[ 0.99917159  0.99856162  0.9232129  ...,  0.99207752  0.96880524\n",
        "  0.96779896]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "2126"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now we need the coordinates of the max estimate\n",
      "# testing here\n",
      "\n",
      "view = phat_words[:, 0]\n",
      "np.argwhere(view == np.max(view))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "array([[6]])"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# may need to tweak this\n",
      "# argwhere returns the indices of the arugment\n",
      "# max along axis 0 gives the max along columns\n",
      "map_estimate = np.argwhere(phat_words == np.max(phat_words, axis=0))\n",
      "# map_estimate = map_estimate.T\n",
      "print(map_estimate.shape)\n",
      "print(map_estimate)\n",
      "print(map_estimate[0])\n",
      "print(map_estimate[0,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(10110, 2)\n",
        "[[   0  555]\n",
        " [   0  556]\n",
        " [   0  577]\n",
        " ..., \n",
        " [  19 8930]\n",
        " [  19 8976]\n",
        " [  19 9022]]\n",
        "[  0 555]\n",
        "0\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phat_words[map_estimate[0,0], map_estimate[0,1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "0.21053096768791343"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phat_words[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "array([  7.33494360e-08,   2.44958046e-02,   6.79892849e-06, ...,\n",
        "         7.01476749e-07,   2.76206470e-06,   2.85116356e-06])"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Classify\n",
      "$Y^{new} = argmax \\big[\\ log_2(P(Y_k)) + \\sum_{i}(\\#\\ of\\ X^{new}_i)log_2(P(X_i|Y_k))\\big]$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_labels = twenty_test.target\n",
      "print(test_labels.size)\n",
      "est_classes = np.zeros((test_labels.size, 20))\n",
      "class_max = np.zeros((test_labels.size, 3))\n",
      "# true labels in first column\n",
      "class_max[:,0] = test_labels.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7532\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_phat_words = np.log2(phat_words)\n",
      "log_class_priors = np.log2(class_priors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc1 = bow_test[0]\n",
      "doc1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "<1x9053 sparse matrix of type '<class 'numpy.int64'>'\n",
        "\twith 29 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(bow_test.shape)\n",
      "print(phat_words.shape)\n",
      "# doc1.dot() is sparse dot product\n",
      "log_class_priors[0] + doc1.dot(log_phat_words[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7532, 9053)\n",
        "(20, 9053)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "array([-223.30574157])"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc_labvec = np.repeat(doc1, 20)\n",
      "print(doc_labvec.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(20,)\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# goal here to return a matrix with shape [samples, features]\n",
      "\n",
      "\n",
      "p = log_phat_words.T + log_class_priors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 95,
       "text": [
        "(9053, 20)"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_log_vals = bow_test.dot(p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_log_vals.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "(7532, 20)"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gives us a vector of class labels for each test document\n",
      "# axis one gives argmax along each ROW. \n",
      "np.argmax(test_log_vals, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 109,
       "text": [
        "array([ 7,  1, 15, ..., 11,  3, 15])"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_labels[np.argmax(test_log_vals, axis=1)].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 111,
       "text": [
        "(7532,)"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 112,
       "text": [
        "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       ..., \n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "7"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab_lookup = {cv_train.vocabulary_[k] : k for k in cv_train.vocabulary_}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "est_classes[20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.])"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}