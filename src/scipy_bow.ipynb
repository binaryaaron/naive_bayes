{
 "metadata": {
  "name": "",
  "signature": "sha256:c1939fb98014e1e2af79da6c2115044b12393c60080e17cd907cc079f87148ab"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twenty_train = fetch_20newsgroups(subset='train',\n",
      "                                  remove=('headers', 'footers', 'quotes'),\n",
      "                                  shuffle=True, random_state=42)\n",
      "twenty_test = fetch_20newsgroups(subset='test',\n",
      "                                  remove=('headers', 'footers', 'quotes'),\n",
      "                                  shuffle=True, random_state=42)\n",
      "twenty_all = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'),\n",
      "                                shuffle=True, random_state=42)\n",
      "twenty_train.target_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 252,
       "text": [
        "['alt.atheism',\n",
        " 'comp.graphics',\n",
        " 'comp.os.ms-windows.misc',\n",
        " 'comp.sys.ibm.pc.hardware',\n",
        " 'comp.sys.mac.hardware',\n",
        " 'comp.windows.x',\n",
        " 'misc.forsale',\n",
        " 'rec.autos',\n",
        " 'rec.motorcycles',\n",
        " 'rec.sport.baseball',\n",
        " 'rec.sport.hockey',\n",
        " 'sci.crypt',\n",
        " 'sci.electronics',\n",
        " 'sci.med',\n",
        " 'sci.space',\n",
        " 'soc.religion.christian',\n",
        " 'talk.politics.guns',\n",
        " 'talk.politics.mideast',\n",
        " 'talk.politics.misc',\n",
        " 'talk.religion.misc']"
       ]
      }
     ],
     "prompt_number": 252
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twenty_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "0",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-312-3d5cfff427c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwenty_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mKeyError\u001b[0m: 0"
       ]
      }
     ],
     "prompt_number": 312
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(twenty_train.target[500])\n",
      "print(twenty_train.data[500])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n",
        "\n",
        "I got one from Microsoft tech support.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(11314, 9053)\n"
       ]
      }
     ],
     "prompt_number": 256
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fit bag of words model to the dataset with specified params\n",
      "cv_train = CountVectorizer(stop_words='english',\n",
      "                     max_df=.95,\n",
      "                     min_df=0.001,\n",
      "                     strip_accents='unicode'\n",
      "                     )\n",
      "bow_train = cv_train.fit_transform(twenty_train.data)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 340
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_test = CountVectorizer(stop_words='english',\n",
      "                     max_df=.95,\n",
      "                     min_df=0.001,\n",
      "                     strip_accents='unicode',\n",
      "                     vocabulary=cv_train.vocabulary_\n",
      "                     )\n",
      "bow_test = cv_test.fit_transform(twenty_test.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 339
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(bow_train.shape)\n",
      "print(bow_test.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(11314, 9053)\n",
        "(7532, 9053)\n"
       ]
      }
     ],
     "prompt_number": 341
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv.get_stop_words()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 342,
       "text": [
        "frozenset({'a',\n",
        "           'about',\n",
        "           'above',\n",
        "           'across',\n",
        "           'after',\n",
        "           'afterwards',\n",
        "           'again',\n",
        "           'against',\n",
        "           'all',\n",
        "           'almost',\n",
        "           'alone',\n",
        "           'along',\n",
        "           'already',\n",
        "           'also',\n",
        "           'although',\n",
        "           'always',\n",
        "           'am',\n",
        "           'among',\n",
        "           'amongst',\n",
        "           'amoungst',\n",
        "           'amount',\n",
        "           'an',\n",
        "           'and',\n",
        "           'another',\n",
        "           'any',\n",
        "           'anyhow',\n",
        "           'anyone',\n",
        "           'anything',\n",
        "           'anyway',\n",
        "           'anywhere',\n",
        "           'are',\n",
        "           'around',\n",
        "           'as',\n",
        "           'at',\n",
        "           'back',\n",
        "           'be',\n",
        "           'became',\n",
        "           'because',\n",
        "           'become',\n",
        "           'becomes',\n",
        "           'becoming',\n",
        "           'been',\n",
        "           'before',\n",
        "           'beforehand',\n",
        "           'behind',\n",
        "           'being',\n",
        "           'below',\n",
        "           'beside',\n",
        "           'besides',\n",
        "           'between',\n",
        "           'beyond',\n",
        "           'bill',\n",
        "           'both',\n",
        "           'bottom',\n",
        "           'but',\n",
        "           'by',\n",
        "           'call',\n",
        "           'can',\n",
        "           'cannot',\n",
        "           'cant',\n",
        "           'co',\n",
        "           'con',\n",
        "           'could',\n",
        "           'couldnt',\n",
        "           'cry',\n",
        "           'de',\n",
        "           'describe',\n",
        "           'detail',\n",
        "           'do',\n",
        "           'done',\n",
        "           'down',\n",
        "           'due',\n",
        "           'during',\n",
        "           'each',\n",
        "           'eg',\n",
        "           'eight',\n",
        "           'either',\n",
        "           'eleven',\n",
        "           'else',\n",
        "           'elsewhere',\n",
        "           'empty',\n",
        "           'enough',\n",
        "           'etc',\n",
        "           'even',\n",
        "           'ever',\n",
        "           'every',\n",
        "           'everyone',\n",
        "           'everything',\n",
        "           'everywhere',\n",
        "           'except',\n",
        "           'few',\n",
        "           'fifteen',\n",
        "           'fify',\n",
        "           'fill',\n",
        "           'find',\n",
        "           'fire',\n",
        "           'first',\n",
        "           'five',\n",
        "           'for',\n",
        "           'former',\n",
        "           'formerly',\n",
        "           'forty',\n",
        "           'found',\n",
        "           'four',\n",
        "           'from',\n",
        "           'front',\n",
        "           'full',\n",
        "           'further',\n",
        "           'get',\n",
        "           'give',\n",
        "           'go',\n",
        "           'had',\n",
        "           'has',\n",
        "           'hasnt',\n",
        "           'have',\n",
        "           'he',\n",
        "           'hence',\n",
        "           'her',\n",
        "           'here',\n",
        "           'hereafter',\n",
        "           'hereby',\n",
        "           'herein',\n",
        "           'hereupon',\n",
        "           'hers',\n",
        "           'herself',\n",
        "           'him',\n",
        "           'himself',\n",
        "           'his',\n",
        "           'how',\n",
        "           'however',\n",
        "           'hundred',\n",
        "           'i',\n",
        "           'ie',\n",
        "           'if',\n",
        "           'in',\n",
        "           'inc',\n",
        "           'indeed',\n",
        "           'interest',\n",
        "           'into',\n",
        "           'is',\n",
        "           'it',\n",
        "           'its',\n",
        "           'itself',\n",
        "           'keep',\n",
        "           'last',\n",
        "           'latter',\n",
        "           'latterly',\n",
        "           'least',\n",
        "           'less',\n",
        "           'ltd',\n",
        "           'made',\n",
        "           'many',\n",
        "           'may',\n",
        "           'me',\n",
        "           'meanwhile',\n",
        "           'might',\n",
        "           'mill',\n",
        "           'mine',\n",
        "           'more',\n",
        "           'moreover',\n",
        "           'most',\n",
        "           'mostly',\n",
        "           'move',\n",
        "           'much',\n",
        "           'must',\n",
        "           'my',\n",
        "           'myself',\n",
        "           'name',\n",
        "           'namely',\n",
        "           'neither',\n",
        "           'never',\n",
        "           'nevertheless',\n",
        "           'next',\n",
        "           'nine',\n",
        "           'no',\n",
        "           'nobody',\n",
        "           'none',\n",
        "           'noone',\n",
        "           'nor',\n",
        "           'not',\n",
        "           'nothing',\n",
        "           'now',\n",
        "           'nowhere',\n",
        "           'of',\n",
        "           'off',\n",
        "           'often',\n",
        "           'on',\n",
        "           'once',\n",
        "           'one',\n",
        "           'only',\n",
        "           'onto',\n",
        "           'or',\n",
        "           'other',\n",
        "           'others',\n",
        "           'otherwise',\n",
        "           'our',\n",
        "           'ours',\n",
        "           'ourselves',\n",
        "           'out',\n",
        "           'over',\n",
        "           'own',\n",
        "           'part',\n",
        "           'per',\n",
        "           'perhaps',\n",
        "           'please',\n",
        "           'put',\n",
        "           'rather',\n",
        "           're',\n",
        "           'same',\n",
        "           'see',\n",
        "           'seem',\n",
        "           'seemed',\n",
        "           'seeming',\n",
        "           'seems',\n",
        "           'serious',\n",
        "           'several',\n",
        "           'she',\n",
        "           'should',\n",
        "           'show',\n",
        "           'side',\n",
        "           'since',\n",
        "           'sincere',\n",
        "           'six',\n",
        "           'sixty',\n",
        "           'so',\n",
        "           'some',\n",
        "           'somehow',\n",
        "           'someone',\n",
        "           'something',\n",
        "           'sometime',\n",
        "           'sometimes',\n",
        "           'somewhere',\n",
        "           'still',\n",
        "           'such',\n",
        "           'system',\n",
        "           'take',\n",
        "           'ten',\n",
        "           'than',\n",
        "           'that',\n",
        "           'the',\n",
        "           'their',\n",
        "           'them',\n",
        "           'themselves',\n",
        "           'then',\n",
        "           'thence',\n",
        "           'there',\n",
        "           'thereafter',\n",
        "           'thereby',\n",
        "           'therefore',\n",
        "           'therein',\n",
        "           'thereupon',\n",
        "           'these',\n",
        "           'they',\n",
        "           'thick',\n",
        "           'thin',\n",
        "           'third',\n",
        "           'this',\n",
        "           'those',\n",
        "           'though',\n",
        "           'three',\n",
        "           'through',\n",
        "           'throughout',\n",
        "           'thru',\n",
        "           'thus',\n",
        "           'to',\n",
        "           'together',\n",
        "           'too',\n",
        "           'top',\n",
        "           'toward',\n",
        "           'towards',\n",
        "           'twelve',\n",
        "           'twenty',\n",
        "           'two',\n",
        "           'un',\n",
        "           'under',\n",
        "           'until',\n",
        "           'up',\n",
        "           'upon',\n",
        "           'us',\n",
        "           'very',\n",
        "           'via',\n",
        "           'was',\n",
        "           'we',\n",
        "           'well',\n",
        "           'were',\n",
        "           'what',\n",
        "           'whatever',\n",
        "           'when',\n",
        "           'whence',\n",
        "           'whenever',\n",
        "           'where',\n",
        "           'whereafter',\n",
        "           'whereas',\n",
        "           'whereby',\n",
        "           'wherein',\n",
        "           'whereupon',\n",
        "           'wherever',\n",
        "           'whether',\n",
        "           'which',\n",
        "           'while',\n",
        "           'whither',\n",
        "           'who',\n",
        "           'whoever',\n",
        "           'whole',\n",
        "           'whom',\n",
        "           'whose',\n",
        "           'why',\n",
        "           'will',\n",
        "           'with',\n",
        "           'within',\n",
        "           'without',\n",
        "           'would',\n",
        "           'yet',\n",
        "           'you',\n",
        "           'your',\n",
        "           'yours',\n",
        "           'yourself',\n",
        "           'yourselves'})"
       ]
      }
     ],
     "prompt_number": 342
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "t = np.arange(10)\n",
      "t = t + 100\n",
      "a = np.arange(10)\n",
      "alog = (np.log(a / t))\n",
      "alog"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "operands could not be broadcast together with shapes (0,) (20,) ",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-136-1fec304e11cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0malog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0malog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,) (20,) "
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# count for document 500\n",
      "print(bow_train[500])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 3810)\t1\n",
        "  (0, 8104)\t1\n",
        "  (0, 7966)\t1\n",
        "  (0, 5286)\t1\n"
       ]
      }
     ],
     "prompt_number": 343
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      }
     ],
     "prompt_number": 344
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twenty_train.target.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 345,
       "text": [
        "11314"
       ]
      }
     ],
     "prompt_number": 345
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class_priors = np.zeros(shape=(20,), dtype='float32')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 346
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "view = twenty_train.target[twenty_train.target == 0]\n",
      "print(view.size/twenty_train.target.size)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.04242531377054976\n"
       ]
      }
     ],
     "prompt_number": 347
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "for idx, lab in enumerate(twenty_train.target_names):\n",
      "    view = twenty_train.target[twenty_train.target == idx]\n",
      "    class_priors[idx] = view.size/twenty_train.target.size\n",
      "    print(lab + ' ' + str(class_priors[idx]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "alt.atheism 0.0424253\n",
        "comp.graphics 0.0516175\n",
        "comp.os.ms-windows.misc 0.0522362\n",
        "comp.sys.ibm.pc.hardware 0.0521478\n",
        "comp.sys.mac.hardware 0.0510871\n",
        "comp.windows.x 0.0524129\n",
        "misc.forsale 0.0517059\n",
        "rec.autos 0.0525013\n",
        "rec.motorcycles 0.0528549\n",
        "rec.sport.baseball 0.0527665\n",
        "rec.sport.hockey 0.0530316\n",
        "sci.crypt 0.0525897\n",
        "sci.electronics 0.0522362\n",
        "sci.med 0.0525013\n",
        "sci.space 0.0524129\n",
        "soc.religion.christian 0.0529433\n",
        "talk.politics.guns 0.0482588\n",
        "talk.politics.mideast 0.0498497\n",
        "talk.politics.misc 0.0410995\n",
        "talk.religion.misc 0.0333215\n"
       ]
      }
     ],
     "prompt_number": 348
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for idx, lab in enumerate(twenty_train.target_names):\n",
      "    print(lab + ' ' + str(class_priors[idx]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "alt.atheism 0.0424253\n",
        "comp.graphics 0.0516175\n",
        "comp.os.ms-windows.misc 0.0522362\n",
        "comp.sys.ibm.pc.hardware 0.0521478\n",
        "comp.sys.mac.hardware 0.0510871\n",
        "comp.windows.x 0.0524129\n",
        "misc.forsale 0.0517059\n",
        "rec.autos 0.0525013\n",
        "rec.motorcycles 0.0528549\n",
        "rec.sport.baseball 0.0527665\n",
        "rec.sport.hockey 0.0530316\n",
        "sci.crypt 0.0525897\n",
        "sci.electronics 0.0522362\n",
        "sci.med 0.0525013\n",
        "sci.space 0.0524129\n",
        "soc.religion.christian 0.0529433\n",
        "talk.politics.guns 0.0482588\n",
        "talk.politics.mideast 0.0498497\n",
        "talk.politics.misc 0.0410995\n",
        "talk.religion.misc 0.0333215\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.where(class_priors > 0.04, 4, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0])"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.unique(bow_train[:,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 91,
       "text": [
        "array([ <11314x1 sparse matrix of type '<class 'numpy.int64'>'\n",
        "\twith 412 stored elements in Compressed Sparse Row format>], dtype=object)"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = bow_train[:,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 349
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 350,
       "text": [
        "1204"
       ]
      }
     ],
     "prompt_number": 350
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this sums all the columns in the sparse matrix into a resulting vector\n",
      "word_sums = bow_train.sum(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 351
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 351
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class_mask1 = twenty_train.target == 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 352
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csums = bow_train[class_mask1].sum(axis=0) + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 353
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twenty_train.target_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 354,
       "text": [
        "['alt.atheism',\n",
        " 'comp.graphics',\n",
        " 'comp.os.ms-windows.misc',\n",
        " 'comp.sys.ibm.pc.hardware',\n",
        " 'comp.sys.mac.hardware',\n",
        " 'comp.windows.x',\n",
        " 'misc.forsale',\n",
        " 'rec.autos',\n",
        " 'rec.motorcycles',\n",
        " 'rec.sport.baseball',\n",
        " 'rec.sport.hockey',\n",
        " 'sci.crypt',\n",
        " 'sci.electronics',\n",
        " 'sci.med',\n",
        " 'sci.space',\n",
        " 'soc.religion.christian',\n",
        " 'talk.politics.guns',\n",
        " 'talk.politics.mideast',\n",
        " 'talk.politics.misc',\n",
        " 'talk.religion.misc']"
       ]
      }
     ],
     "prompt_number": 354
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(word_sums + 1)\n",
      "print(word_sums)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1535  954   17 ...,   22   69   32]]\n",
        "[[1534  953   16 ...,   21   68   31]]\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csums / (word_sums + 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 99,
       "text": [
        "matrix([[ 0.0228013 ,  0.01886792,  0.05882353, ...,  0.09090909,\n",
        "          0.01449275,  0.03125   ]])"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## okay, now put it together for maximum likelihood\n",
      "\n",
      "## preallocate array, 20 row, word dic length\n",
      "phat_words = np.zeros((20, bow_train.shape[1]), dtype='float64')\n",
      "\n",
      "## create sum vectors and assign them to the correct spot\n",
      "## may need to fiddle with smoothing params\n",
      "for idx, lab in enumerate(twenty_train.target_names):\n",
      "    c_mask = twenty_train.target == idx\n",
      "    c_sum = bow_train[c_mask].sum(axis=0)\n",
      "    c_sum = c_sum + 1\n",
      "    # print(c_sum/word_sums)\n",
      "    phat_words[idx] = (c_sum / (word_sums + 20))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(phat_words[10] > 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 101,
       "text": [
        "13208"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now we have probability of the prior classes (p(c))\n",
      "\n",
      "# and p(w|c)\n",
      "\n",
      "# we need cmap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(phat_words[:,0])\n",
      "print(phat_words.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.002574    0.02252252  0.02187902  0.02059202  0.00772201  0.07078507\n",
        "  0.41377091  0.01415701  0.01994852  0.12870013  0.07593308  0.02767053\n",
        "  0.02059202  0.02767053  0.02767053  0.03603604  0.01801802  0.02187902\n",
        "  0.01866152  0.0032175 ]\n",
        "(20, 13208)\n"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this is a sanity check; all should sum to one\n",
      "c_map = np.sum(phat_words, axis=0)\n",
      "print(c_map.shape)\n",
      "print(c_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(13208,)\n",
        "[ 1.  1.  1. ...,  1.  1.  1.]\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now we need the coordinates of the max estimate\n",
      "# testing here\n",
      "\n",
      "view = phat_words[:, 0]\n",
      "np.argwhere(view == np.max(view))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 141,
       "text": [
        "array([[6]])"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# may need to tweak this\n",
      "# argwhere returns the indices of the arugment\n",
      "# max along axis 0 gives the max along columns\n",
      "map_estimate = np.argwhere(phat_words == np.max(phat_words, axis=0))\n",
      "# map_estimate = map_estimate.T\n",
      "print(map_estimate.shape)\n",
      "print(map_estimate)\n",
      "print(map_estimate[0])\n",
      "print(map_estimate[0,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(14334, 2)\n",
        "[[    0   242]\n",
        " [    0   260]\n",
        " [    0   262]\n",
        " ..., \n",
        " [   19 12970]\n",
        " [   19 12998]\n",
        " [   19 13134]]\n",
        "[  0 242]\n",
        "0\n"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phat_words[map_estimate[0,0], map_estimate[0,1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 157,
       "text": [
        "0.14999999999999999"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Cannot find a common data type.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-218-a1030e701e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbow_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mValueError\u001b[0m: Cannot find a common data type."
       ]
      }
     ],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%aimport bayes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phat_words = bayes.phat_word_est(bow_train, class_labels=twenty_train.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "estimating params with Dirchlet Prior:\n",
        "\t vocabsize = 11314.000000\n",
        "\t beta = 0.000088\n",
        "\t alpha = 1.000088\n",
        "\t denominator = 1.000000\n"
       ]
      }
     ],
     "prompt_number": 355
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phat_words[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 362,
       "text": [
        "array([  7.33494360e-08,   2.44958046e-02,   6.79892849e-06, ...,\n",
        "         7.01476749e-07,   2.76206470e-06,   2.85116356e-06])"
       ]
      }
     ],
     "prompt_number": 362
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Classify\n",
      "$Y^{new} = argmax \\big[\\ log_2(P(Y_k)) + \\sum_{i}(\\#\\ of\\ X^{new}_i)log_2(P(X_i|Y_k))\\big]$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.log2(phat_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 230,
       "text": [
        "array([[-23.70063889,  -5.35132151, -17.16626117, ..., -20.44310138,\n",
        "        -18.46582146, -18.42001777],\n",
        "       [ -5.53437281,  -5.85381873, -17.16626117, ..., -20.44310138,\n",
        "         -2.41501625, -18.42001777],\n",
        "       [ -6.06488535,  -7.85378685, -17.16626117, ..., -20.44310138,\n",
        "         -4.99987249,  -1.36922318],\n",
        "       ..., \n",
        "       [ -7.42744429,  -2.25888188, -17.16626117, ...,  -2.2768353 ,\n",
        "        -18.46582146, -18.42001777],\n",
        "       [ -6.32791833,  -3.71086899, -17.16626117, ...,  -3.97726398,\n",
        "        -18.46582146, -18.42001777],\n",
        "       [-10.23468992,  -6.26885268, -17.16626117, ...,  -5.97721617,\n",
        "        -18.46582146, -18.42001777]])"
       ]
      }
     ],
     "prompt_number": 230
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_labels = twenty_test.target\n",
      "print(test_labels.size)\n",
      "est_classes = np.zeros((test_labels.size, 20))\n",
      "class_max = np.zeros((test_labels.size, 3))\n",
      "# true labels in first column\n",
      "class_max[:,0] = test_labels.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7532\n"
       ]
      }
     ],
     "prompt_number": 363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(bow_test.shape)\n",
      "print(twenty_test.data[0])\n",
      "print(len(twenty_test.data[0].strip().split()))\n",
      "\n",
      "\n",
      "print(bow_test[0, :].toarray())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7532, 9053)\n",
        "I am a little confused on all of the models of the 88-89 bonnevilles.\n",
        "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
        "differences are far as features or performance. I am also curious to\n",
        "know what the book value is for prefereably the 89 model. And how much\n",
        "less than book value can you usually get them for. In other words how\n",
        "much are they in demand this time of year. I have heard that the mid-spring\n",
        "early summer is the best time to buy.\n",
        "92\n",
        "[[0 0 0 ..., 0 0 0]]\n"
       ]
      }
     ],
     "prompt_number": 364
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc1 = bow_test[0].toarray()\n",
      "np.sum(doc1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 377,
       "text": [
        "34"
       ]
      }
     ],
     "prompt_number": 377
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The above is okay due to the dictionary chaning based on stemming and so on.\n",
      "# I'm guessing i'll have issues based on \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 337
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.dot(doc1, np.log2(phat_words[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 378,
       "text": [
        "array([-218.74681071])"
       ]
      }
     ],
     "prompt_number": 378
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "for i, row in enumerate(phat_words[:,0]):\n",
      "    est_classes[0,i] = np.dot(doc1, np.log2(phat_words[i]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 382
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.argmax(est_classes[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 386,
       "text": [
        "7"
       ]
      }
     ],
     "prompt_number": 386
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab_lookup = {cv_train.vocabulary_[k] : k for k in cv_train.vocabulary_}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 331
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 332
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}